{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import bz2\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import dlib\n",
    "import pandas as pd\n",
    "import stone \n",
    "from imutils import face_utils\n",
    "from scipy.spatial import distance\n",
    "from imutils import face_utils \n",
    "import os\n",
    "import stone\n",
    "import stone\n",
    "import colorspacious as cs\n",
    "from matplotlib import colors as mcolor\n",
    "from skimage import color,io "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting the right files to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "images = os.listdir(\"/Users/user/Downloads/skin color with computer vision/facesforexperiment2\")\n",
    "folder_path = '/Users/user/Downloads/skin color with computer vision/facesforexperiment2/'\n",
    "image_list2 = [[f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png'))]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initializing the face detetor and facial landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the detector and landmarks for measurements\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "landmarks_predictor = dlib.shape_predictor(\"/Users/user/Downloads/skin color with computer vision/shape_predictor_81_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unziping the file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) \n",
    "    if os.path.isfile(os.path.join(folder_path, f)) and f.endswith(('.jpg', '.png'))]\n",
    "image_list2.extend(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in image_files:\n",
    "    image_path = os.path.join(folder_path, image_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distance function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating distance and updating Dataframe\n",
    "\n",
    "def calculate_distance_and_update_dataframe(landmarks, landmarks1, landmarks2, column_name, idx):\n",
    "    x1,  y1 = landmarks.part(landmarks1).x, landmarks.part(landmarks1).y\n",
    "    x2, y2 = landmarks.part(landmarks2).x, landmarks.part(landmarks2).y\n",
    "    \n",
    "    distance_value = distance.euclidean((x1,y1), (x2, y2))\n",
    "    dataframe.at[idx, column_name]= distance_value\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using the tip of the nose to divide images for asymmetry comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def calculate_facial_symmetry(landmarks, landmark1, landmark2, img):\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    midpoint_x = (landmarks.part(landmark1).x + landmarks.part(landmark2).x) // 2\n",
    "    \n",
    "    midpoint_x = min(max(midpoint_x, 0), w)\n",
    "    \n",
    "    right_part = img[:,:midpoint_x]\n",
    "    left_part = img[:, midpoint_x:]\n",
    "    \n",
    "    cv2.imshow(\"right_part\",right_part)\n",
    "    cv2.imshow(\"left_part\",left_part)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in image_files:\n",
    "    try:\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        \n",
    "        your_image = cv2.imread(image_path)\n",
    "        \n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        faces = detector(rgb_image)\n",
    "        \n",
    "        if faces:\n",
    "            face = faces[0]\n",
    "            \n",
    "            landmarks = landmarks_predictor(rgb_image,face)\n",
    "            \n",
    "            calculate_facial_symmetry(landmarks, 27, 8, img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        else:\n",
    "            print(f\"Error: Could not load image at {image_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "    break\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### uses the stone(skin tone) library to get hex code of skin color detected in photo\n",
    "### transforms the hex code to rgb, then finally to CIELAB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb_to_cie(image_path, idx):\n",
    "    # for idx, image_name in enumerate(image_path):\n",
    "    \n",
    "    try:\n",
    "        current_image = image_path\n",
    "        output = stone.process(current_image, image_type='color', return_report_image=True)\n",
    "        \n",
    "        if output is not None:\n",
    "            get_output = output.get('faces', [])\n",
    "            \n",
    "            if get_output:\n",
    "                skin_tone = get_output[0].get('skin_tone', None)\n",
    "                \n",
    "                if skin_tone:\n",
    "                    skin_tone_2 = skin_tone.lstrip('#')\n",
    "                    \n",
    "                    # Convert skin tone hex to RGB and normalize\n",
    "                    rgb2 = tuple(int(skin_tone_2[i:i + 2], 16) for i in (0, 2, 4))\n",
    "                    rgb2 = np.array(rgb2) / 255\n",
    "                    \n",
    "                    # Converting RGB to CIE\n",
    "                    lab = color.rgb2lab(rgb2[np.newaxis, np.newaxis, :])[0][0]\n",
    "                    lab = np.round(lab, 2)\n",
    "                    \n",
    "                    print(f\"skin tone: {skin_tone} cielab: {lab}  at {current_image}\")\n",
    "            else:\n",
    "                print(f\"output at {idx} is not found\")\n",
    "        else:\n",
    "            print(f\"image at {idx} failed\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"error processing image {idx}: {e}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calling the get_rgb_cie function, setting a disired amount of files to test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_amount = 10\n",
    "image_count = 0\n",
    "for idx, image_group in enumerate(image_list2):\n",
    "    for im in image_group:  # Process each image in the group\n",
    "        try:\n",
    "            # Construct full image path\n",
    "            image_path = os.path.join('/Users/user/Downloads/skin color with computer vision/facesforexperiment2/', im)\n",
    "            get_rgb_to_cie(image_path, idx)\n",
    "            image_count += 1\n",
    "            if image_count >= desired_amount:\n",
    "                break\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"error processing image {im}: {str(e)}\")\n",
    "\n",
    "    # Break after first group for testing purposes\n",
    "    if image_count >= desired_amount:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  craniofacial distance and Craniofacial area\n",
    "dataframe = pd.DataFrame({\n",
    "\"Image Name\": [None] * len(images),\n",
    "'Head Height': [0.0] * len(images),  \n",
    "'Face Height': [0.0] * len(images),\n",
    "'Face Height 2': [0.0] * len(images),\n",
    "'Face Height 3': [0.0] * len(images),\n",
    "'Face Width': [0.0] * len(images),\n",
    "'Face Width 2': [0.0] * len(images),\n",
    "'Orbits Intercanthal Width': [0.0] * len(images),\n",
    "'Orbits Fissure Length(left and right)': [0.0] * len(images),\n",
    "'Orbits Biocular Width': [0.0] * len(images),\n",
    "'Nose Height': [0.0] * len(images),\n",
    "'Nose Width': [0.0] * len(images),\n",
    "'Labio-oral region':[0.0] * len(images),\n",
    "'Intercanthal Face Height': [0.0] * len(images),\n",
    "'eye fissure height (left and right)': [0.0] * len(images),\n",
    "'orbit and brow height (left and right)': [0.0] * len(images),\n",
    "'Columella Length': [0.0] * len(images),\n",
    "'Upper Lip Height': [0.0] * len(images),\n",
    "'Lower Vermilion Height': [0.0] * len(images),\n",
    "'Philtrum Width': [0.0] * len(images),\n",
    "'lateral upper lip heights (left and right)': [0.0] * len(images),\n",
    "'Lower Face Height': [0.0] * len(images),\n",
    "'Upper Vermilion Height': [0.0] * len(images)\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the measurement columns once outside the loop\n",
    "measurement_columns = [\n",
    "    'Head Height', 'Face Height', 'Face Height 2', 'Face Height 3', 'Face Width', 'Face Width 2',\n",
    "    'Orbits Intercanthal Width', 'Orbits Fissure Length(left and right)', 'Orbits Biocular Width',\n",
    "    'Nose Height', 'Nose Width', 'Labio-oral region', 'Intercanthal Face Height',\n",
    "    'eye fissure height (left and right)', 'orbit and brow height (left and right)', 'Columella Length',\n",
    "    'Upper Lip Height', 'Lower Vermilion Height', 'Philtrum Width', 'lateral upper lip heights (left and right)',\n",
    "    'Lower Face Height','Upper Vermilion Height'\n",
    "]\n",
    "\n",
    "\n",
    "dataframe = pd.DataFrame({col: [np.nan] * len(images) for col in measurement_columns})\n",
    "dataframe['Image Name'] = [None] * len(images)\n",
    "\n",
    "for idx, im in enumerate(images):\n",
    "    try:\n",
    "        # Skip DS_Store\n",
    "        if im == \"DS_Store\":\n",
    "            continue\n",
    "        \n",
    "        # Read and check the image\n",
    "        image_path = '/Users/user/Downloads/skin color with computer vision/facesforexperiment2/' + im\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Check if image loaded successfully\n",
    "        if image is None:\n",
    "            print(f\"Unable to read image {im}\")\n",
    "            dataframe.loc[idx, measurement_columns] = np.nan  \n",
    "            continue  \n",
    "\n",
    "        # Store the image name in the dataframe\n",
    "        dataframe.at[idx, \"Image Name\"] = im\n",
    "        \n",
    "        # Convert the image to RGB color space and detect faces\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        faces = detector(rgb_image)\n",
    "        \n",
    "        # Ensure that at least one face is detected before proceeding\n",
    "        if len(faces) == 0:\n",
    "            print(f\"No face detected in image {im}\")\n",
    "            dataframe.loc[idx, measurement_columns] = np.nan \n",
    "            continue\n",
    "        \n",
    "        # Get the first face detected\n",
    "        face = faces[0]\n",
    "        landmarks = landmarks_predictor(rgb_image, face)\n",
    "        \n",
    "        # Perform distance calculations and update the DataFrame\n",
    "        calculate_distance_and_update_dataframe(landmarks, 71, 27, 'Head Height', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 71, 8, 'Face Height', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 27, 8, 'Face Height 2', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 33, 8, 'Face Height 3', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 2, 14, 'Face Width', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 5, 11, 'Face Width 2', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 39, 42, 'Orbits Intercanthal Width', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 39, 36, 'Orbits Fissure Length(left and right)', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 36, 45, 'Orbits Biocular Width', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 27, 33, 'Nose Height', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 31, 35, 'Nose Width', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 48, 54, 'Labio-oral region', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 27, 66, 'Intercanthal Face Height', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 38, 41, 'eye fissure height (left and right)', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 19, 41, 'orbit and brow height (left and right)', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 33, 30, 'Columella Length', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 33, 66, 'Upper Lip Height', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 66, 57, 'Lower Vermilion Height', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 49, 53, 'Philtrum Width', idx)\n",
    "        calculate_distance_and_update_dataframe(landmarks, 32, 62, 'lateral upper lip heights (left and right)', idx)\n",
    "        # distance between stomion and gnathion\n",
    "        calculate_distance_and_update_dataframe(landmarks, 66, 8, 'Lower Face Height', idx)\n",
    "        # distance between stomion and libiale superious\n",
    "        calculate_distance_and_update_dataframe(landmarks, 62, 66, 'Upper Vermilion Height', idx)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {im}: {str(e)}\")\n",
    "        dataframe.loc[idx, measurement_columns] = np.nan \n",
    "        continue  # Continue to the next image in case of an error\n",
    "\n",
    "# Show the DataFrame\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Facial index'] = dataframe['Face Height 2']/dataframe['Face Width']\n",
    "dataframe['Mandibular index'] = dataframe['Lower Face Height']/dataframe['Face Width 2']\n",
    "dataframe['Intercanthal index'] = dataframe['Orbits Intercanthal Width']/dataframe['Orbits Biocular Width']\n",
    "dataframe['Orbital width index (left and right)'] = dataframe['Orbits Fissure Length(left and right)']/dataframe['Orbits Intercanthal Width']\n",
    "dataframe['Eye fissure index (left and right)'] = dataframe['eye fissure height (left and right)']/dataframe['Orbits Fissure Length(left and right)']\n",
    "dataframe['Nasal index'] = dataframe['Nose Width']/dataframe['Nose Height']\n",
    "dataframe['Vermilion height index '] = dataframe['Upper Vermilion Height']/dataframe['Lower Vermilion Height']\n",
    "dataframe['Mouth-face width index'] = dataframe['Labio-oral region']/dataframe['Face Width']\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Typology Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ita_values = []\n",
    "\n",
    "\n",
    "for image_file in image_files:\n",
    "    \n",
    "    image_path = os.path.join(folder_path, image_file)\n",
    "\n",
    "    your_image = cv2.imread(image_path)\n",
    "    # Resize the image to reduce memory usage\n",
    "    your_image = cv2.resize(your_image, (500, 500))  # Resize to 500x500 pixels\n",
    "\n",
    "    \n",
    "    lab_img = color.rgb2lab(your_image.astype('uint8'))\n",
    "\n",
    "    \n",
    "    ita_values = []\n",
    "\n",
    "    for pixel in lab_img.reshape((-1, 3)):\n",
    "        L, a, b = pixel\n",
    "\n",
    "        if L > 0:  \n",
    "            ita = np.arctan((L - 50) / b) * (180 / np.pi)\n",
    "            ita_values.append(ita)\n",
    "\n",
    "    average_ita = np.mean(ita_values)\n",
    "\n",
    "\n",
    "    average_ita_values.append(average_ita)\n",
    "\n",
    "\n",
    "# Check if lengths match before adding to dataframe\n",
    "if len(average_ita_values) < len(dataframe):\n",
    "    average_ita_values.extend([np.nan] * (len(dataframe) - len(average_ita_values)))\n",
    "elif len(average_ita_values) > len(dataframe):\n",
    "    average_ita_values = average_ita_values[:len(dataframe)]\n",
    "\n",
    "dataframe['Average_ITA'] = average_ita_values\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
